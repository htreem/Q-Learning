{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/hoganma/.local/lib/python3.7/site-packages (0.17.1)\n",
      "Requirement already satisfied: scipy in /Users/hoganma/opt/anaconda3/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /Users/hoganma/.local/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /Users/hoganma/opt/anaconda3/lib/python3.7/site-packages (from gym) (1.19.0)\n",
      "Requirement already satisfied: six in /Users/hoganma/opt/anaconda3/lib/python3.7/site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /Users/hoganma/opt/anaconda3/lib/python3.7/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: future in /Users/hoganma/opt/anaconda3/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation spaces:  Box(6,)\n",
      "Action spaces:  Discrete(3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "#env_name = \"MountainCar-v0\"\n",
    "#env_name = \"MountainCarContinuous-v0\"\n",
    "#env_name = \"Pendulum-v0\"\n",
    "#env_name = \"Acrobot-v1\"\n",
    "env = gym.make(env_name) #handle for interacting with the environment\n",
    "print(\"Observation spaces: \",env.observation_space) \n",
    "print(\"Action spaces: \", env.action_space) \n",
    "type(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understand continuous and discrete data; alternatives are for finding value in different data sets\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self,env):\n",
    "        self.is_discrete = type(env.action_space) == gym.spaces.discrete.Discrete\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            self.action_size = env.action_space.n \n",
    "            print(\"Action size: \", self.action_size)\n",
    "        \n",
    "        else:\n",
    "            self.action_low = env.action_space.low\n",
    "            self.action_high = env.action_space.high\n",
    "            self.action_space = env.action_space.shape\n",
    "            print(\"Action range: \", self.action_low,self.action_high) \n",
    "            \n",
    "    #pick the action that the agent does\n",
    "    def get_action(self,state):\n",
    "        if self.is_discrete:\n",
    "            action= random.choice(range(self.action_size))\n",
    "        else:\n",
    "            action = np.random.uniform(self.action_low, self.action_high, self.action_space)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action size:  3\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(env)\n",
    "state = env.reset() \n",
    "\n",
    "#iterate through a bunch of time steps; at each time step, action is taken\n",
    "for i in range(20):\n",
    "    state = env.reset()\n",
    "    for i in range(200):\n",
    "        action = agent.get_action(state)\n",
    "        state, reward, done, info = env.step(action)#apply action to env\n",
    "        env.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
